name: TDD Circuit Breaker

on:
  # Check health every 30 minutes (optimized from 15 min to reduce GitHub Actions usage)
  schedule:
    - cron: '*/30 * * * *'

  # Manual trigger for testing
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode (simulate failure condition)'
        required: false
        type: boolean
        default: false

# Security: Define minimal required permissions
permissions:
  actions: write # To check workflow runs AND disable/enable workflows
  issues: write # To create incident issues
  contents: read # To read repository

jobs:
  check-health:
    name: ðŸ” Check TDD Pipeline Health
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Analyze recent workflow runs
        id: analyze
        env:
          GH_TOKEN: ${{ github.token }}
          TEST_MODE: ${{ github.event.inputs.test_mode || 'false' }}
        run: |
          echo "ðŸ“Š Analyzing TDD pipeline health..."

          # Check if in test mode
          if [ "$TEST_MODE" = "true" ]; then
            echo "âš ï¸  TEST MODE: Simulating high failure rate"
            FAILURES=8
            TOTAL=10
            RETRY_ISSUES=5
          else
            # Get last 10 workflow runs from claude-tdd.yml
            RECENT_RUNS=$(gh run list \
              --repo ${{ github.repository }} \
              --workflow="claude-tdd.yml" \
              --limit 10 \
              --json conclusion,createdAt,displayTitle)

            # Count total runs
            TOTAL=$(echo "$RECENT_RUNS" | jq 'length')

            # Count failures (including cancelled which often means timeout)
            FAILURES=$(echo "$RECENT_RUNS" | jq '[.[] | select(.conclusion == "failure" or .conclusion == "cancelled")] | length')

            # Count specs currently in retry state
            # Query each label separately since --search OR syntax is unreliable
            RETRY_1=$(gh issue list --repo ${{ github.repository }} --label "infrastructure-retry:1" --json number --jq 'length')
            RETRY_2=$(gh issue list --repo ${{ github.repository }} --label "infrastructure-retry:2" --json number --jq 'length')
            RETRY_3=$(gh issue list --repo ${{ github.repository }} --label "infrastructure-retry:3" --json number --jq 'length')
            RETRY_ISSUES=$((RETRY_1 + RETRY_2 + RETRY_3))
          fi

          # Calculate failure rate
          if [ "$TOTAL" -eq 0 ]; then
            FAILURE_RATE=0
            echo "âš ï¸  No recent runs found"
          else
            FAILURE_RATE=$((FAILURES * 100 / TOTAL))
            echo "ðŸ“ˆ Recent runs: $TOTAL"
            echo "âŒ Failures: $FAILURES"
            echo "ðŸ”„ Issues in retry: $RETRY_ISSUES"
            echo "ðŸ“Š Failure rate: ${FAILURE_RATE}%"
          fi

          # Output results
          echo "failure_rate=$FAILURE_RATE" >> $GITHUB_OUTPUT
          echo "failures=$FAILURES" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "retry_issues=$RETRY_ISSUES" >> $GITHUB_OUTPUT

          # Determine if circuit should open
          # Open if: >50% failure rate OR >5 issues in retry state
          if [ "$TOTAL" -ge 5 ] && [ "$FAILURE_RATE" -gt 50 ]; then
            echo "should_open_circuit=true" >> $GITHUB_OUTPUT
            echo "ðŸš¨ CIRCUIT BREAKER THRESHOLD EXCEEDED: ${FAILURE_RATE}% failure rate"
          elif [ "$RETRY_ISSUES" -gt 5 ]; then
            echo "should_open_circuit=true" >> $GITHUB_OUTPUT
            echo "ðŸš¨ CIRCUIT BREAKER THRESHOLD EXCEEDED: $RETRY_ISSUES issues requiring retries"
          else
            echo "should_open_circuit=false" >> $GITHUB_OUTPUT
            echo "âœ… Pipeline health is acceptable"
          fi

      - name: Check circuit breaker status
        id: circuit_status
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "ðŸ” Checking circuit breaker status..."

          # Check if circuit breaker is already open (workflow disabled)
          STATUS=$(gh workflow list \
            --repo ${{ github.repository }} \
            --all \
            --json name,state \
            --jq '.[] | select(.name == "TDD Queue - Processor") | .state')

          if [ "$STATUS" = "disabled_manually" ]; then
            echo "is_open=true" >> $GITHUB_OUTPUT
            echo "âš ï¸  Circuit breaker is currently OPEN (queue processor disabled)"
          else
            echo "is_open=false" >> $GITHUB_OUTPUT
            echo "âœ… Circuit breaker is currently CLOSED (queue processor active)"
          fi

      - name: Open circuit breaker (disable queue)
        if: steps.analyze.outputs.should_open_circuit == 'true' && steps.circuit_status.outputs.is_open != 'true'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "ðŸš¨ Opening circuit breaker - disabling queue processor..."

          # Disable the queue processor workflow
          gh workflow disable "tdd-queue-processor.yml" --repo ${{ github.repository }}

          echo "âœ… Queue processor disabled"

          # Create incident issue
          ISSUE_BODY="## ðŸš¨ TDD Automation Circuit Breaker Activated

          **Failure Rate**: ${{ steps.analyze.outputs.failure_rate }}%
          **Recent Runs**: ${{ steps.analyze.outputs.failures }}/${{ steps.analyze.outputs.total }} failed
          **Issues in Retry**: ${{ steps.analyze.outputs.retry_issues }}
          **Timestamp**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Action Taken**: Queue processor workflow disabled

          ### Possible Causes
          - Claude Code API issues or rate limiting
          - GitHub Actions runner issues (workflow_dispatch failures)
          - Network/CDN problems
          - Recent code changes breaking automation
          - Systematic retry failures (workflow_dispatch API issues)

          ### Investigation Steps
          1. Check recent failed runs: [claude-tdd.yml runs](https://github.com/${{ github.repository }}/actions/workflows/claude-tdd.yml)
          2. Check issues requiring retries: \`gh issue list --label \"infrastructure-retry:1\"\` (and retry:2, retry:3)
          3. Look for patterns in error types (timeout, installation, API errors, workflow_dispatch failures)
          4. Check Claude Code service status
          5. Review recent changes to workflow files

          ### Recovery
          Once the issue is resolved:
          1. Re-enable the queue processor: \`gh workflow enable tdd-queue-processor.yml\`
          2. Close this issue to indicate resolution
          3. Monitor the next few runs to ensure stability
          4. Check if retry monitor is recovering stuck retries

          ---
          *ðŸ¤– Automated Circuit Breaker*"

          gh issue create \
            --repo ${{ github.repository }} \
            --title "ðŸš¨ TDD Circuit Breaker: High Failure Rate Detected" \
            --body "$ISSUE_BODY" \
            --label "tdd-automation,incident,priority:high"

      - name: Close circuit breaker (enable queue)
        if: steps.analyze.outputs.should_open_circuit == 'false' && steps.circuit_status.outputs.is_open == 'true'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "âœ… Failure rate recovered - closing circuit breaker..."

          # Re-enable the queue processor workflow
          gh workflow enable "tdd-queue-processor.yml" --repo ${{ github.repository }}

          echo "âœ… Queue processor re-enabled"

          # Find and close any open circuit breaker issues
          OPEN_ISSUES=$(gh issue list \
            --repo ${{ github.repository }} \
            --label "incident" \
            --state open \
            --json number,title \
            --jq '.[] | select(.title | contains("TDD Circuit Breaker")) | .number')

          if [ -n "$OPEN_ISSUES" ]; then
            for ISSUE in $OPEN_ISSUES; do
              gh issue comment "$ISSUE" \
                --repo ${{ github.repository }} \
                --body "âœ… **Circuit Breaker Recovered**

              **Current Failure Rate**: ${{ steps.analyze.outputs.failure_rate }}%
              **Recent Runs**: ${{ steps.analyze.outputs.failures }}/${{ steps.analyze.outputs.total }} failed
              **Timestamp**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
              **Action**: Queue processor re-enabled

              The TDD automation pipeline has recovered and is operating normally.

              ---
              *ðŸ¤– Automated Circuit Breaker*"

              gh issue close "$ISSUE" --repo ${{ github.repository }}
              echo "âœ… Closed incident issue #$ISSUE"
            done
          fi

      - name: Generate health report
        if: always()
        run: |
          echo "ðŸ“Š TDD Pipeline Health Report"
          echo "============================"
          echo "Failure Rate: ${{ steps.analyze.outputs.failure_rate }}%"
          echo "Recent Runs: ${{ steps.analyze.outputs.failures }}/${{ steps.analyze.outputs.total }} failed"
          echo "Issues in Retry: ${{ steps.analyze.outputs.retry_issues }}"
          echo "Circuit Status: ${{ steps.circuit_status.outputs.is_open == 'true' && 'OPEN (queue disabled)' || 'CLOSED (queue active)' }}"
          echo "Thresholds:"
          echo "  - Failure rate: >50% (opens circuit)"
          echo "  - Retry issues: >5 (opens circuit)"
          echo "Recovery: <50% failure rate AND â‰¤5 retry issues (closes circuit)"

          # Add warning if approaching threshold
          FAILURE_RATE="${{ steps.analyze.outputs.failure_rate }}"
          RETRY_ISSUES="${{ steps.analyze.outputs.retry_issues }}"
          if [ "$FAILURE_RATE" -ge 30 ] && [ "$FAILURE_RATE" -lt 50 ]; then
            echo ""
            echo "âš ï¸  WARNING: Failure rate approaching circuit breaker threshold"
            echo "   Consider investigating recent failures before circuit opens"
          fi
          if [ "$RETRY_ISSUES" -ge 3 ] && [ "$RETRY_ISSUES" -le 5 ]; then
            echo ""
            echo "âš ï¸  WARNING: Multiple issues requiring retries ($RETRY_ISSUES)"
            echo "   This may indicate infrastructure issues with workflow_dispatch"
          fi
